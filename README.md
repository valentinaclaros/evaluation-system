# ğŸ“Š Sistema de EvaluaciÃ³n del DesempeÃ±o

Sistema completo de evaluaciÃ³n del desempeÃ±o automatizado para auditar llamadas de cancelaciones de tarjetas de crÃ©dito y cuentas de ahorro, con anÃ¡lisis automÃ¡tico de impacto de feedbacks.

![Status](https://img.shields.io/badge/status-active-success.svg)
![Python](https://img.shields.io/badge/python-3.8+-blue.svg)
![License](https://img.shields.io/badge/license-MIT-blue.svg)

## ğŸ¯ CaracterÃ­sticas Principales

### âœ… AuditorÃ­as de Llamadas
- Registro completo de llamadas con customer ID
- ClasificaciÃ³n por nivel de criticidad (baja, media, alta, crÃ­tica)
- Tipos de error y descripciones detalladas
- CalificaciÃ³n TNPS (promoter, neutral, detractor, null)
- Sistema de filtros avanzado

### âœ… GestiÃ³n de Feedbacks
- Registro estructurado de feedback a agentes
- DefiniciÃ³n de planes de acciÃ³n
- **AnÃ¡lisis automÃ¡tico de impacto pre/post feedback**
- ComparaciÃ³n de errores antes y despuÃ©s
- CÃ¡lculo de porcentaje de mejora

### âœ… Dashboard y AnÃ¡lisis
- Vista general con mÃ©tricas clave
- DesempeÃ±o individual por agente
- DistribuciÃ³n visual de TNPS
- AnÃ¡lisis de tipos de errores mÃ¡s comunes
- Ranking de agentes por desempeÃ±o
- IdentificaciÃ³n de necesidades de capacitaciÃ³n

### âœ… Plan Individual de Desarrollo
- Seguimiento de mejora continua
- IdentificaciÃ³n de brechas de desempeÃ±o
- VisualizaciÃ³n de progreso post-feedback

## ğŸš€ Inicio RÃ¡pido

### Requisitos
- Python 3.8+
- pip

### InstalaciÃ³n

```bash
# 1. Clonar el repositorio
git clone https://github.com/TU_USUARIO/TU_REPOSITORIO.git
cd TU_REPOSITORIO

# 2. Crear entorno virtual
python3 -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# 3. Instalar dependencias
pip install -r requirements.txt

# 4. Inicializar con datos de ejemplo (opcional)
python init_sample_data.py

# 5. Iniciar servidor
python main.py
```

O simplemente usa el script automÃ¡tico:
```bash
./start_server.sh
```

Visita: **http://localhost:8000**

## ğŸ“¸ Screenshots

### Dashboard
Vista general con mÃ©tricas clave del equipo

### AuditorÃ­as
Registro y seguimiento de todas las llamadas auditadas

### AnÃ¡lisis de Impacto
ComparaciÃ³n automÃ¡tica de desempeÃ±o antes y despuÃ©s de feedbacks

## ğŸ—ï¸ Arquitectura

### Backend
- **Framework**: FastAPI
- **Base de Datos**: SQLite (migrable a PostgreSQL)
- **ORM**: SQLAlchemy
- **ValidaciÃ³n**: Pydantic

### Frontend
- HTML5 + CSS3 + JavaScript
- DiseÃ±o moderno y responsivo
- Single Page Application (SPA)

## ğŸ“š DocumentaciÃ³n

- [**DocumentaciÃ³n Completa**](README_PERFORMANCE_SYSTEM.md) - InformaciÃ³n tÃ©cnica detallada
- [**GuÃ­a RÃ¡pida**](GUIA_RAPIDA.md) - Tutorial paso a paso de uso
- [**Resumen del Sistema**](RESUMEN_SISTEMA.md) - Resumen ejecutivo
- [**GuÃ­a de ProducciÃ³n**](PRODUCCION_DEPLOYMENT.md) - Deploy a producciÃ³n

## ğŸ”‘ Funcionalidad Estrella

### AnÃ¡lisis AutomÃ¡tico de Impacto de Feedback

El sistema puede analizar automÃ¡ticamente si un feedback fue efectivo:

1. Registras un feedback a un agente
2. Esperas un perÃ­odo (recomendado: 30 dÃ­as)
3. Click en "Analizar"
4. El sistema automÃ¡ticamente:
   - âœ… Cuenta errores 30 dÃ­as ANTES del feedback
   - âœ… Cuenta errores 30 dÃ­as DESPUÃ‰S del feedback
   - âœ… Calcula porcentaje de mejora
   - âœ… Identifica si el agente mejorÃ³ o empeorÃ³

**Resultados claros:**
- âœ… +50%: Excelente mejora
- âœ… +20%: Buena mejora
- ğŸŸ¡ +10%: Leve mejora
- ğŸ”´ Negativo: EmpeorÃ³ (necesita mÃ¡s atenciÃ³n)

## ğŸ“Š API Endpoints

### Agentes
- `POST /api/agents/` - Crear agente
- `GET /api/agents/` - Listar agentes
- `GET /api/agents/{id}` - Obtener agente especÃ­fico

### AuditorÃ­as
- `POST /api/audits/` - Crear auditorÃ­a
- `GET /api/audits/` - Listar con filtros
- `GET /api/audits/{id}` - Obtener auditorÃ­a

### Feedbacks
- `POST /api/feedbacks/` - Crear feedback
- `GET /api/feedbacks/` - Listar feedbacks
- `POST /api/feedbacks/{id}/analyze` - **Analizar impacto automÃ¡ticamente**

### AnÃ¡lisis
- `GET /api/analytics/dashboard` - EstadÃ­sticas generales
- `GET /api/analytics/agents/{id}/performance` - DesempeÃ±o de agente
- `GET /api/analytics/agents/ranking` - Ranking de agentes

## ğŸ¯ Casos de Uso

1. **Auditar Llamadas**: Registra y clasifica cada llamada por criticidad y tipo de error
2. **Dar Feedback Efectivo**: Proporciona retroalimentaciÃ³n estructurada con plan de acciÃ³n
3. **Medir Impacto**: Analiza objetivamente si tus intervenciones estÃ¡n funcionando
4. **Identificar Patrones**: Encuentra tipos de errores comunes y necesidades de capacitaciÃ³n
5. **Reconocer Mejoras**: Identifica y reconoce a agentes que estÃ¡n mejorando

## ğŸ” Seguridad

Para uso en producciÃ³n, consulta [PRODUCCION_DEPLOYMENT.md](PRODUCCION_DEPLOYMENT.md) para:
- MigraciÃ³n a PostgreSQL
- ImplementaciÃ³n de autenticaciÃ³n JWT
- ConfiguraciÃ³n de HTTPS
- Sistema de roles y permisos
- Backups automÃ¡ticos

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. Por favor:
1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## ğŸ“ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para mÃ¡s detalles.

## ğŸ‘¥ Autores

- **Valentina Claros** - *Desarrollo inicial*

## ğŸ™ Agradecimientos

- FastAPI por el excelente framework
- Comunidad de Python por las librerÃ­as utilizadas
- DiseÃ±o inspirado en herramientas modernas de SaaS

## ğŸ“ Soporte

Para preguntas, problemas o sugerencias:
- Abre un [Issue](../../issues)
- Consulta la [documentaciÃ³n](README_PERFORMANCE_SYSTEM.md)
- Revisa la [guÃ­a rÃ¡pida](GUIA_RAPIDA.md)

---

**Desarrollado para optimizar el proceso de evaluaciÃ³n del desempeÃ±o y mejora continua de agentes de call center** ğŸš€

