# Sistema de EvaluaciÃ³n del DesempeÃ±o Automatizado

Sistema completo para auditar llamadas de cancelaciones de tarjetas de crÃ©dito y cuentas de ahorro, registrar feedback a agentes y analizar la mejora en su desempeÃ±o.

## ğŸ¯ CaracterÃ­sticas Principales

### 1. **GestiÃ³n de Metas y OKRs**
- Crea y asigna metas de forma masiva
- Gestiona y da seguimiento del progreso y cumplimiento
- Notifica o envÃ­a mensajes
- Gestiona permisos para asignar o editar

### 2. **AuditorÃ­as de Llamadas**
- Registra auditorÃ­as con:
  - Fecha de la llamada
  - Customer ID
  - Agente que atendiÃ³
  - Auditor que revisÃ³
  - Tipo de error encontrado
  - Nivel de criticidad (baja, media, alta, crÃ­tica)
  - CalificaciÃ³n TNPS (promoter, neutral, detractor, null)
  - Notas adicionales

### 3. **GestiÃ³n de Feedback**
- Registra feedback estructurado a agentes
- Define planes de acciÃ³n
- AnÃ¡lisis automÃ¡tico de impacto pre/post feedback
- Compara errores antes y despuÃ©s del feedback

### 4. **AnÃ¡lisis y Reportes**
- Dashboard con mÃ©tricas generales
- Vista de desempeÃ±o por agente
- Ranking de agentes por menor tasa de error
- DistribuciÃ³n de TNPS
- AnÃ¡lisis de errores por tipo
- Tendencias de mejora

### 5. **Plan Individual de Desarrollo**
- Visualiza el progreso de cada agente
- Identifica brechas de desempeÃ±o
- Cierra brechas identificadas en las evaluaciones

## ğŸ“‹ Requisitos

- Python 3.8+
- pip (gestor de paquetes de Python)

## ğŸš€ InstalaciÃ³n y Uso

### 1. Instalar dependencias

```bash
cd /Users/valentina.claros/Desktop/Query
pip install -r requirements.txt
```

### 2. Inicializar base de datos con datos de ejemplo (opcional)

```bash
python init_sample_data.py
```

Este script crearÃ¡:
- 5 agentes de ejemplo
- 2 auditores
- 50 auditorÃ­as de llamadas con datos variados
- 10 feedbacks con anÃ¡lisis de impacto

### 3. Iniciar el servidor

```bash
python main.py
```

El servidor se iniciarÃ¡ en: **http://localhost:8000**

### 4. Acceder al sistema

Abre tu navegador y visita: **http://localhost:8000**

## ğŸ“Š Uso del Sistema

### Dashboard
Al iniciar, verÃ¡s:
- Total de agentes activos
- Total de auditorÃ­as realizadas
- Total de feedbacks entregados
- Errores crÃ­ticos
- Tasa de error promedio
- DistribuciÃ³n de TNPS
- Top 10 agentes con menor tasa de error

### GestiÃ³n de Agentes
1. Click en "Agentes" en el menÃº lateral
2. Click en "Nuevo Agente" para agregar
3. Completa: nombre, email, departamento, cargo
4. Guarda y el agente estarÃ¡ disponible para auditorÃ­as

### Registrar AuditorÃ­as de Llamadas
1. Click en "AuditorÃ­as"
2. Click en "Nueva AuditorÃ­a"
3. Completa el formulario:
   - Fecha y hora de la llamada
   - Customer ID
   - Tipo de llamada (tarjeta de crÃ©dito o cuenta de ahorros)
   - Agente que atendiÃ³
   - Auditor que revisÃ³
   - Nivel de criticidad
   - Tipo y descripciÃ³n del error (si aplica)
   - CalificaciÃ³n TNPS del cliente
   - Notas adicionales
4. Guarda la auditorÃ­a

### Entregar Feedback a Agentes
1. Click en "Feedbacks"
2. Click en "Nuevo Feedback"
3. Selecciona el agente
4. Ingresa fecha, tÃ­tulo y descripciÃ³n del feedback
5. Define un plan de acciÃ³n (opcional)
6. Guarda el feedback

### Analizar Impacto del Feedback
1. En la secciÃ³n de "Feedbacks"
2. Click en "Analizar" en el feedback deseado
3. El sistema automÃ¡ticamente:
   - Cuenta errores 30 dÃ­as antes del feedback
   - Cuenta errores 30 dÃ­as despuÃ©s del feedback
   - Calcula el porcentaje de mejora
   - Muestra si el agente mejorÃ³ o empeorÃ³

### Ver AnÃ¡lisis de DesempeÃ±o por Agente
1. Click en "AnÃ¡lisis"
2. Selecciona un agente del dropdown
3. Visualiza:
   - Total de llamadas atendidas
   - Total de errores cometidos
   - Tasa de error
   - Score TNPS
   - DistribuciÃ³n de TNPS (promotores, neutrales, detractores)
   - Errores por tipo
   - Historial de feedbacks con anÃ¡lisis de mejora

## ğŸ”§ API Endpoints

### Agentes
- `POST /api/agents/` - Crear agente
- `GET /api/agents/` - Listar agentes
- `GET /api/agents/{id}` - Obtener agente especÃ­fico
- `PUT /api/agents/{id}/deactivate` - Desactivar agente

### Auditores
- `POST /api/auditors/` - Crear auditor
- `GET /api/auditors/` - Listar auditores

### AuditorÃ­as
- `POST /api/audits/` - Crear auditorÃ­a
- `GET /api/audits/` - Listar auditorÃ­as (con filtros)
- `GET /api/audits/{id}` - Obtener auditorÃ­a especÃ­fica

Filtros disponibles:
- `agent_id` - Filtrar por agente
- `auditor_id` - Filtrar por auditor
- `start_date` - Desde fecha
- `end_date` - Hasta fecha
- `criticality` - Nivel de criticidad

### Feedbacks
- `POST /api/feedbacks/` - Crear feedback
- `GET /api/feedbacks/` - Listar feedbacks
- `GET /api/feedbacks/{id}` - Obtener feedback especÃ­fico
- `PUT /api/feedbacks/{id}` - Actualizar feedback
- `POST /api/feedbacks/{id}/analyze` - Analizar impacto del feedback

### AnÃ¡lisis
- `GET /api/analytics/dashboard` - EstadÃ­sticas generales
- `GET /api/analytics/agents/{id}/performance` - DesempeÃ±o de agente
- `GET /api/analytics/agents/ranking` - Ranking de agentes

## ğŸ“ Estructura del Proyecto

```
Query/
â”œâ”€â”€ main.py                 # Servidor FastAPI y endpoints
â”œâ”€â”€ database.py            # Modelos de base de datos
â”œâ”€â”€ schemas.py             # Schemas de validaciÃ³n
â”œâ”€â”€ requirements.txt       # Dependencias
â”œâ”€â”€ init_sample_data.py    # Script para datos de ejemplo
â”œâ”€â”€ performance_evaluation.db  # Base de datos SQLite (se crea al iniciar)
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ index.html        # Interfaz principal
â”‚   â”œâ”€â”€ css/
â”‚   â”‚   â””â”€â”€ styles.css    # Estilos
â”‚   â””â”€â”€ js/
â”‚       â””â”€â”€ app.js        # LÃ³gica del frontend
â””â”€â”€ README_PERFORMANCE_SYSTEM.md  # Esta documentaciÃ³n
```

## ğŸ¨ Casos de Uso

### Caso 1: Identificar Agentes con Problemas
1. Ve al Dashboard
2. Observa la tasa de error promedio
3. Revisa el ranking de agentes
4. Identifica agentes con alta tasa de error o baja calificaciÃ³n TNPS

### Caso 2: Dar Seguimiento a Mejora DespuÃ©s de Feedback
1. Entrega un feedback a un agente especÃ­fico
2. Espera al menos 30 dÃ­as
3. Click en "Analizar" en el feedback
4. Revisa el porcentaje de mejora
5. Toma decisiones basadas en datos

### Caso 3: Auditar y Clasificar Errores
1. Registra cada llamada auditada
2. Clasifica el nivel de criticidad
3. Describe el tipo de error
4. Registra la satisfacciÃ³n del cliente (TNPS)
5. Usa los filtros para identificar patrones

### Caso 4: Evaluar DesempeÃ±o Individual
1. Ve a "AnÃ¡lisis"
2. Selecciona un agente
3. Revisa todas sus mÃ©tricas
4. Observa los tipos de errores mÃ¡s comunes
5. Revisa el impacto de feedbacks anteriores
6. Planifica prÃ³ximas acciones de desarrollo

## ğŸ” Datos de Seguridad

- La base de datos es SQLite (archivo local)
- Para producciÃ³n, considera migrar a PostgreSQL o MySQL
- Implementa autenticaciÃ³n si el sistema serÃ¡ expuesto a internet
- Los datos sensibles deben ser encriptados en producciÃ³n

## ğŸš€ MigraciÃ³n a ProducciÃ³n

Para llevar este sistema a producciÃ³n:

1. **Base de datos**: Cambia SQLite por PostgreSQL
   ```python
   SQLALCHEMY_DATABASE_URL = "postgresql://user:password@localhost/performance_db"
   ```

2. **Servidor**: Usa Gunicorn o similar
   ```bash
   gunicorn main:app -w 4 -k uvicorn.workers.UvicornWorker
   ```

3. **Variables de entorno**: Usa variables de entorno para configuraciÃ³n sensible

4. **AutenticaciÃ³n**: Implementa JWT o OAuth2

5. **HTTPS**: Usa certificados SSL/TLS

## ğŸ’¡ PrÃ³ximas Mejoras Sugeridas

- [ ] Exportar reportes a Excel/PDF
- [ ] GrÃ¡ficos interactivos con Chart.js
- [ ] Notificaciones por email
- [ ] IntegraciÃ³n con calendario para seguimiento de feedbacks
- [ ] Sistema de roles y permisos
- [ ] Historial de cambios y auditorÃ­a
- [ ] Dashboard personalizable
- [ ] PredicciÃ³n de desempeÃ±o con ML

## ğŸ“ Soporte

Para preguntas o problemas, revisa los logs en la consola donde iniciaste el servidor.

---

**Desarrollado para optimizar el proceso de evaluaciÃ³n del desempeÃ±o y mejora continua de agentes de call center.**

